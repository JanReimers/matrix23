Design objectives:
    1) Start with zero based indexing
        Add in FORTRAN 1 based (or arbitrary lower bounds) indexing.  Do this last so that all the internal work is done with zero
        based indexing.
    2) This allows us to use size_t for all indexing integers
    Done: 3) Support the same matrix packing arrangements used by Lapack and Blas for full, triangular (U/L), band, tri-diagonal and diagonal matrices.
        Done: Isolate all the packing and unpacking code into a isPacker and isShaper concepts and groups of classes.
        Done: The subscriptor really has two aspects:
            1) The shape which determines which indexes (i,j) are assumed to zero (regardes of weather or not those zeros are actually stored).
            2) The packing determines arrangements of the elements.  i.e. how (i,j) are layed in linear memory.
        Usually packing follows from shape.  But Lapack and Blas support for example triangular shape with full storage.  i.e. part of matrix is allocated
        but unused.  There must be reasons for this.  Program complexity may be one of them.
        For each type we have a virtual size nr*nc and a packed size.  Packed size is probably only needed for data array construction.
    Done: 4) Support symmetric symmetries using triangular packing.
        This adds a third aspect to matrix storage, symmetry.  
        only a certain subset of combinations make sense.  Each of these three aspects would have and agent in the Matrix class that does the required work.
    4.1) Support Hermitian symmetries using triangular packing.
    5) Use std::vector<T> and std::valarray<T> interchangably for storing the raw data.  
        Also support a Copy-On-Write array?
    6) Support overloaded operators with lazy (delayed) evaluation
        As much as possible use ranges and view adaptors instead of traditional expression templates to achieve lazy evaluation.
        Matrix*Matrix should take advantage packing type.  For example DiagonalMatrix * DiagonalMatrix is O(N) not O(N^3)!
    7) Support float, double, std::complex<T> data types.
    Done: 8-1) Support various initialization type: none, zero, one, value, random
    8-2) Support initialization diagonal=value, unit.
    Done: 9) Use c++23.  Huge convenience of zip, zip_transform view adaptors.
    Done: 10) Make some blasmm(Matrix,Matrix) functions for speed comparison
    11) Support ascii/binary io with the cereal header library.
        Need to learn how to get cmake to hanlde optional dependencies first.  Optional for cereal, lapack, blas ...
    12) No traditional for loops like:  for (size_t i = 0; i < nrows; ++i)
    13) No new/delete

TODO priorities:
    -clean up
        shapers.hpp, packers.hpp symmetry.hpp
        GenVector and Data<>.  Use default template arguments like for matrix.

    -Missing features:
        -op+ op- */ scalars, +=,-=,*=,/=;.
        -TransposeView
        -SubMatrixView (this is not a slice row(i), col(j) and diagonal are slices, 2D->1D)
        -op= code and tests.  i.e.  FullMatrixCM C;C=A*B;

    -Test Triangular shape with full storage.
        add blas support for full packing U*U L*L.
    -Get cmake to handle optional dependencies first.  Optional for cereal, lapack, blas ...
        https://cmake.org/cmake/help/latest/guide/using-dependencies/index.html
        https://cmake.org/cmake/help/book/mastering-cmake/cmake/Help/guide/using-dependencies/
Bugs:
    -blas RM*RM not working.  
        https://petewarden.com/2015/10/25/an-engineers-guide-to-gemm/


Notes for documenting:
    overloaded op are all delayed evaluation.  blas calls are all eager evaluation with posible construction of temporaries.
        So we cannot put blas calls inside overloaded operators.  User must explicitely choose.
    Code is generic accross all combos of packings/shapes/symmetris.  So will not be optimized for any given pair.




---------------------------------------------------------------------------------------------------------------------------------------
TODO priorities:
    Done: -Specialized MatrixFullCMProductView<R,C> for max performance.
          n       blas::gemm(ms)        ranges(ms)         std_mmul           mmul_wcopy
        100          0.5( 0.3)          0.6( 0.3)          0.4( 0.3)          0.1( 0.1)      
        200          1.1( 0.1)          7.1( 0.1)          7.0( 0.0)          6.8( 0.1)      
        300          5.1( 0.1)         25.5( 0.2)         25.9( 0.2)         25.2( 0.2)      
        400         11.9( 0.4)         61.3( 1.5)         75.4( 2.3)         66.1( 6.0)      
        500         21.6( 0.6)        114.7( 4.0)        135.6( 4.5)        111.2( 3.1)      
        600         35.6( 0.3)        193.1( 4.9)       1017.8( 8.1)        189.4( 1.0)      
        700         59.7( 1.8)        361.7(28.8)       2298.1(28.2)        379.0(45.6)    
    Done: -Still need to add symmetry
        Should symmetry be read only?  i.e. assingments are only allowed on the top half of a symmetric matrix?.
            If not then how do we overload op(i,j) for a hermitian matrix?  conj(double) is not a rvalue.  We need to return a proxy with rvalue semantics.
            struct conj_proxy{T& re, T& im}.
        When is symmtry applied?
            1) only on unstored values?  I.e. return m(j,i) if m(i,j) is not stored?
                In this case NoSymmetry needs to return 0 for unstored values and Symmetric needs to return op(j,i) when reading op(i,j)
            2) Try and enforce symmetry on a full storage matrix?  Then we need to intercep rvalue op(i,j) instead of read only op(i,j).
            #1 sounds MUCH easier.
        Yes: -Can we have packer.create_shaper();
            No: to avoid all the Shaper pair rules?
    -clean up
        Done: value_t should be value_type to be consistent with std::vector and std::valarray.
        Done: add nr(), nc() to shaper concept.
        Done: Remove stored_row_size/stored_col_size from packer concept?
        Done: One init loop for Matrix construction.

Issues:
    
    -What are the rules for propagating Indexing (col/row major) through a matrix product?
        At the moment We don't even store the attribute.
        Fixed: Using lambdas for row/col major indexing is a little sketchy.
        Also we need mirror image row(i)/col(j) implementations for row/col major indexing.  More lambdas?
            Yes: or throw in the towel and make distincte FullPackerRM, FullPackerCM classes? 
    Fixed: -Lots of duplication with nr/nc when creating packers and shapers.
    
    No: -Move default op(i,j) based row(i)/col(j) in the PackerCommon
        Then make efficient override for full matrix using chunk & stride view adaptors.
        These overrides need to know the Indexing option.
    -Clean up files.  exentsion hpp sux
Performance:
    -Observation: Nothing beats blas::dgemm ... not even close!!!
        blas is very hard to match :https://stackoverflow.com/questions/1303182/how-does-blas-get-such-extreme-performance
    Done: -Make a simple op(i,j) version to compare
        n       blas::gemm(ms)        ranges(ms)         std_mmul           mmul_wcopy
        100          0.0( 0.0)          1.4( 0.6)          1.0( 0.5)          0.1( 0.1)      
        200          1.0( 0.0)          6.8( 0.1)          7.0( 0.2)          6.9( 0.1)      
        300          5.0( 0.2)         26.0( 0.6)         25.5( 0.5)         25.1( 0.7)      
        400         10.7( 0.2)         69.3( 1.0)         68.8( 1.3)         55.6( 0.8)      
        500         21.6( 0.4)        137.7( 7.3)        143.0( 8.1)        113.2( 3.8)      
        600         36.6( 0.8)       1016.5( 7.8)       1018.5(12.5)        197.3(10.9)      
        700         56.6( 0.5)       2243.4( 3.2)       2244.1( 6.5)        304.8( 0.4)       
     Done: Think of a clean way to allow user to opt for the blas call.
            No: 1) global flag  matrix23::blas_on()/blas_off()
                put and if statement in op*(M,M)
            Done: 2) op*(M,M) always does ranges. user must choose for hot code ares: blasmm(M,M), blasmv(M,V), blasvm(V,M) 
                Construct of temporaries for chained calls.  No way to avoid that.
    -Is there a nice way to get the wcopy algo wirking with ranges?
        for (size_t i=0;i<A.nr();i++)
        {
            Vector<double> Ai=A.row(i);
            for (size_t j=0;j<B.nc();j++)
            {
                double t=0.0;
                for (size_t k=0;k<A.nc();k++)
                    t+=Ai(k)*B(k,j);
                C(i,j)=t;
            }
        }
        Yes!!   Cache  VecotrView Ai=a_rows[i] and i,  i didnt' change use the cache.
            Need CM(i,j) and RM(i,j) ops  RM caches b_rows[j],j instead.
            value_t operator()(size_t i, size_t j) const
            {
                return a_rows[i]*b_cols[j]; //VectorView*VectorView
            }
            Need to set a limit on when this is used.  n>nmin_for_cache.
        Here is the result:
          n       blas::gemm(ms)        ranges(ms)         std_mmul           mmul_wcopy
        100          0.0( 0.0)          1.0( 0.0)          0.0( 0.0)          0.0( 0.0)      
        200          1.1( 0.1)         11.5( 0.2)          7.4( 0.2)          7.4( 0.2)      
        300          6.2( 0.4)         49.1( 6.7)         31.4( 2.3)         28.5( 2.8)      
        400         11.5( 0.5)         77.2( 1.3)         70.4( 1.1)         57.4( 1.0)      
        500         22.1( 0.7)        154.6( 5.5)        142.1( 6.9)        111.2( 2.8)      
        600         35.5( 0.4)        254.6( 3.9)       1030.6( 9.2)        188.8( 0.5)      
        700         57.0( 0.7)        405.2( 3.0)       2268.2( 7.7)        314.5( 2.0)

        Now ranges beats std_mmul (naive mul) for large enough n (>500) but still not as good as mmul_wcopy.  for n<=500 is it the overall looser.  This mostly because of the
        indices intersection handling required for non-full packed matrices.  To get around this we need a specialized MatrixProductView for FullMatrixCM*FullMatrixCM and another
        one for FullMatrixRM*FullMatrixRM that does do indices intersection analisys.  There are two ways to acived this:
            1) Make special op*(FullMatrixCM,FullMatrixCM) that returns MatrixFullCMProductView<R,C>
            2) Expand MatrixProductView to take both packer types (instead of auto p=MatrixProductPacker(a.packer(),b.packer())) and then make template specializations for FullCM/RM.
        Option 1 seems better because MatrixFullCMProductView<R,C> can inherit from MatrixProductView<R,C,P,S> and only need to overload op(i,j).
            It might help to have specialized concepts for FullCM and FullRM.  But what is the distinguishing function call (or attribute) then distinguished them?
            The specialization is the other way around.  Non full needs is_stored for the packer, full does not.
        Tiling https://siboehm.com/articles/22/Fast-MMM-on-CPU
    https://github.com/flame/how-to-optimize-gemm/wiki#the-gotoblasblis-approach-to-optimizing-matrix-matrix-multiplication---step-by-step



Done: -Numerous overloaded operators (+ - *scalar etc) for Vector return a VectorView<std::ranges::viewable_range R>
 where R varies depending on operator history. We return VectorView instead of viewable_range so that all operators
 only got called for isVector arguments.
 Since these are all 1D operations, It would nice to use the same overloaded ops for Matrix + Matrix.  But then they need to return
 a MatrixView instead of a VectorView.  One idea is for Matrix and MatrixView to define a type view_t = MatrixView<R>
 but matrix does not know R it just knows template <std::ranges::viewable_range R> MatrixView

 Done: - op+(isVector a, isVector b) should calculate the union of the a.indices and b.indices, thus skipping over zeros (a[i]==0 && b[i]==0)

 -Fortran storage:
 
      real A(3,5)
defines a two-dimensional array of 3*5=15 real numbers. It is useful to think of the first index as the row index, and the second as the column index. Hence we get the graphical picture:

   (1,1)  (1,2)  (1,3)  (1,4)  (1,5)
   (2,1)  (2,2)  (2,3)  (2,4)  (2,5)
   (3,1)  (3,2)  (3,3)  (3,4)  (3,5)

   2-dimensional arrays are stored by column. So in the above example, array element (1,2) will follow element (3,1).
Band matrices.  For let us just deal with square banded matrices.  from Lapack docs:
Normally:
!>          AB is DOUBLE PRECISION array, dimension (LDAB,N)
!>          On entry, the upper or lower triangle of the symmetric band
!>          matrix A, stored in the first KD+1 rows of the array.  The
!>          j-th column of A is stored in the j-th column of the array AB
!>          as follows:
!>          if UPLO = 'U', AB(KD+1+i-j,j) = A(i,j) for max(1,j-KD)<=i<=j;
!>          if UPLO = 'L', AB(1+i-j,j)    = A(i,j) for j<=i<=min(N,j+KD).
!>          See below for further details.
!>
!>          On exit, if INFO = 0, the triangular factor U or L from the
!>          Cholesky factorization A = U**T*U or A = L*L**T of the band
!>          matrix A, in the same storage format as A.
!>
!>  The band storage scheme is illustrated by the following example, when
!>  N = 6, KD = 2, and UPLO = 'U':
!>
!>  On entry:                       On exit:
!>
!>      *    *   a13  a24  a35  a46      *    *   u13  u24  u35  u46
!>      *   a12  a23  a34  a45  a56      *   u12  u23  u34  u45  u56
!>     a11  a22  a33  a44  a55  a66     u11  u22  u33  u44  u55  u66
!>
!>  Similarly, if UPLO = 'L' the format of A is as follows:
!>
!>  On entry:                       On exit:
!>
!>     a11  a22  a33  a44  a55  a66     l11  l22  l33  l44  l55  l66
!>     a21  a32  a43  a54  a65   *      l21  l32  l43  l54  l65   *
!>     a31  a42  a53  a64   *    *      l31  l42  l53  l64   *    *
!>
!>  Array elements marked * are not used by the routine.
!> 


!>          On entry, the matrix A in band storage, in rows KL+1 to
!>          2*KL+KU+1; rows 1 to KL of the array need not be set.
!>          The j-th column of A is stored in the j-th column of the
!>          array AB as follows:
!>          AB(KL+KU+1+i-j,j) = A(i,j) for max(1,j-KU)<=i<=min(N,j+KL)
!>          On exit, details of the factorization: U is stored as an
!>          upper triangular band matrix with KL+KU superdiagonals in
!>          rows 1 to KL+KU+1, and the multipliers used during the
!>          factorization are stored in rows KL+KU+2 to 2*KL+KU+1.
!>
!>  The band storage scheme is illustrated by the following example, when
!>  M = N = 6, KL = 2, KU = 1:
!>
!>  On entry:                       On exit:
!>
!>      *    *    *    +    +    +       *    *    *   u14  u25  u36
!>      *    *    +    +    +    +       *    *   u13  u24  u35  u46
!>      *   a12  a23  a34  a45  a56      *   u12  u23  u34  u45  u56
!>     a11  a22  a33  a44  a55  a66     u11  u22  u33  u44  u55  u66
!>     a21  a32  a43  a54  a65   *      m21  m32  m43  m54  m65   *
!>     a31  a42  a53  a64   *    *      m31  m42  m53  m64   *    *
!>
!>  Array elements marked * are not used by the routine; elements marked
!>  + need not be set on entry, but are required by the routine to store
!>  elements of U because of fill-in resulting from the row interchanges.



Design:
    Packer: storage_size(), is_stored(i,j), offset(i,j), stored_row_size(i), stored_col_size(j)
    Shape:  nonzero_row_indexes(j) nonzero_col_indexes(i)
    Symmetry: constrains (i,j)=(j,i) ... if (j,i) is not stored return (i,j) instread of zero.
